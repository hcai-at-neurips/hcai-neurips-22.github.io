<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>HCAI @ NeurIPS Workshop '22 | Program</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
        integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css"
        integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w=="
        crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <link rel="stylesheet" href="stylesheets/style.css">
</head>

<body>
    <nav class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark"><span class="navbar-brand">HCAI @ NeurIPS
            '22</span><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navBarNav"
            aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation menu"><span
                class="navbar-toggler-icon"></span></button>
        <div class="collapse navbar-collapse" id="navBarNav">
            <ul class="navbar-nav mr-auto">
                <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
                <li class="nav-item"><a class="nav-link" href="call.html">Call for Participation</a></li>
                <li class="nav-item"><a class="nav-link active" href="program.html">Program<span
                            class="sr-only">(current)</span></a></li>
                <li class="nav-item"><a class="nav-link" href="organizers.html">Organizers</a></li>
            </ul>
        </div>
    </nav>
    <div class="nav-spacer"></div>
    <div class="banner bg-dark">
        <div class="text-center text-light">
            <h1>HCAI @ NeurIPS '22</h1>
            <h3>Virtual Workshop on Human-Centered AI Workshop at NeurIPS</h3>
            <h4>Online on 9 December 2022</h4>
        </div>
    </div>
    <div class="container">
        <div class="row">
            <div class="col-md-8">
                <div class="card-spacer"></div>
                <div class="card bg-light">
                    <div class="card-body">
                        <h1>Program</h1>
                        <table class="program">
                            <tr>
                                <td class="align-center">Start<br />(CET)</td>
                                <td class="align-center">End<br />(CET)</td>
                                <td class="align-center">Start<br />(EDT)</td>
                                <td class="align-center">End<br />(EDT)</td>
                                <td class="align-right">Session Name</td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">14:00</td>
                                <td class="text-light session-time">14:15</td>
                                <td class="text-light session-time">8:00</td>
                                <td class="text-light session-time">8:15</td>
                                <td class="text-light session-name"><strong>Introduction</strong></td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="authors">by Organizers</p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">14:15</td>
                                <td class="text-light session-time">14:30</td>
                                <td class="text-light session-time">8:15</td>
                                <td class="text-light session-time">8:30</td>
                                <td class="text-light session-name"><strong>Keynote 1</strong></td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="title">"Living with AI"</p>
                                    <p class="authors">by Joonhwan Lee, Seoul National University, South Korea.</p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">14:30</td>
                                <td class="text-light session-time">14:35</td>
                                <td class="text-light session-time">8:30</td>
                                <td class="text-light session-time">8:35</td>
                                <td class="text-light session-name"><strong>discussion</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">14:35</td>
                                <td class="text-light session-time">14:50</td>
                                <td class="text-light session-time">8:35</td>
                                <td class="text-light session-time">8:40</td>
                                <td class="text-light session-name"><strong>Panel 1: Explainable AI (XAI)</strong></td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #24</p>
                                    <p class="title">"Closing the Creator-Consumer Gap in XAI: A Call for Participatory
                                        XAI Design with End-users"</p>
                                    <p class="authors">by Sunnie S. Y. Kim, Elizabeth Anne Watkins, Olga Russakovsky,
                                        Ruth Fong, Andr√©s Monroy-Hern√°ndez</p>
                                    <p class="abstract">Abstract: Despite the proliferation of explainable AI (XAI)
                                        methods, little is understood about end-users' explainability needs and
                                        perceptions of existing XAI approaches. To address this gap, we interviewed 20
                                        end-users of a real-world AI application, and found that end-users' AI and
                                        domain background play a critical role in shaping their XAI needs and
                                        perceptions. Further, end-users surfaced gaps in current XAI research and
                                        offered valuable suggestions. In this position paper, we reflect on our findings
                                        and make the case for participatory XAI, especially involving end-users in the
                                        XAI design process, towards developing &quot;explanations (XAI) that serve the
                                        needs of diverse end-users.&quot;</p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #55</p>
                                    <p class="title">"Rethinking Explainability as a Dialogue: A Practitioner‚Äôs
                                        Perspective"</p>
                                    <p class="authors">by Dylan Z Slack, Satyapriya Krishna, Himabindu Lakkaraju, Sameer
                                        Singh</p>
                                    <p class="abstract">Abstract: While there is considerable interest in explainability
                                        within the machine learning community, the utility of explanations for domain
                                        experts in high-stakes fields, such as doctors and policy makers, is currently
                                        not well understood. To help fill this gap, we carry out a study where we
                                        interview doctors, healthcare professionals, and policymakers about where
                                        explanations fall short and how they could be improved going forward. Our
                                        findings indicate that decision-makers are often unsatisfied with current
                                        techniques that provide one-off explanations, like feature importances and
                                        rule-lists, and would strongly prefer interactive explanations. Further, they
                                        agree explanations in the form of open-ended natural language dialogues would
                                        achieve these goals. As a way to move forward, we outline a set of principles
                                        researchers should follow when designing interactive explanations, demonstrate
                                        how natural language dialogues satisfy these principles, and encourage the
                                        community to pursue research in explainability through natural language
                                        dialogues.</p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #70</p>
                                    <p class="title">"A Thematic Comparison of Human and AI Explanations of Sexism
                                        Assessment"</p>
                                    <p class="authors">by Sharon Ferguson, Paula Akemi Aoyagui, Rohan Alexander,
                                        Anastasia Kuzminykh</p>
                                    <p class="abstract">Abstract: Recent developments in Artificial Intelligence (AI)
                                        show much promise for algorithmic decision-making. In many scenarios,
                                        specifically those open-to-interpretation, scholars suggest that the
                                        collaboration between humans and AI may result in maximum complementary
                                        performance. To enable this collaboration, AI must be able to explain the
                                        rationale behind decisions in a way that is understandable to humans, though it
                                        is not yet clear what this means. In this work, we discuss the first step
                                        towards a criteria for understandable, natural-language AI explanations by
                                        comparing the thematic content of human and AI explanations. We highlight
                                        results that point to both promising potential as well as concerning challenges.
                                    </p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">14:50</td>
                                <td class="text-light session-time">14:55</td>
                                <td class="text-light session-time">8:50</td>
                                <td class="text-light session-time">8:55</td>
                                <td class="text-light session-name"><strong>discussion</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">14:55</td>
                                <td class="text-light session-time">15:10</td>
                                <td class="text-light session-time">8:55</td>
                                <td class="text-light session-time">9:10</td>
                                <td class="text-light session-name"><strong>Keynote 2</strong></td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="title">"Human-Centered Co-Creative AI: From Inspirational to Responsible
                                        AI"</p>
                                    <p class="authors">by Mary Lou Maher, University of North Carolina Charlotte, US.
                                    </p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">15:10</td>
                                <td class="text-light session-time">15:15</td>
                                <td class="text-light session-time">9:10</td>
                                <td class="text-light session-time">9:15</td>
                                <td class="text-light session-name"><strong>discussion</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">15:15</td>
                                <td class="text-light session-time">15:30</td>
                                <td class="text-light session-time">9:15</td>
                                <td class="text-light session-time">9:20</td>
                                <td class="text-light session-name"><strong>Panel 2: Large Models</strong></td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #45</p>
                                    <p class="title">"User and Technical Perspectives of Controllable Code Generation"
                                    </p>
                                    <p class="authors">by Stephanie Houde, Vignesh Radhakrishna, Praneeth Reddy, Juie
                                        Darwade, Haoran Hu, Kalpesh Krishna, Mayank Agarwal, Kartik Talamadupula, Justin
                                        D. Weisz</p>
                                    <p class="abstract">Abstract: Large language models (LLM) such as OpenAI Codex are
                                        increasingly being applied to software engineering tasks to generate code for a
                                        variety of purposes including code authoring and code translation.
                                        Human-centered research in this domain has revealed that software engineers
                                        would like the ability to influence or control the properties of generated code
                                        so as to optimize output for their particular code base and application needs.
                                        In this work, we explore user requirements for controllable code generation and
                                        show that human-written code is more optimal than standard beam-search code
                                        outputs from a large language model.</p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #72</p>
                                    <p class="title">"Towards an Understanding of Human-AI Interaction in Prompt-Based
                                        Co-Creative Systems"</p>
                                    <p class="authors">by Atefeh Mahdavi Goloujeh, Anne Sullivan, Brian Magerko</p>
                                    <p class="abstract">Abstract: Co-creative AI (Artificial Intelligence) has witnessed
                                        unprecedented growth in text-to-image generative systems. In this paper, we
                                        posit that a better understanding of the drivers of user interaction with
                                        prompt-based co-creative AI tools will significantly improve how they are
                                        designed for, used by, and explained to current and future users. Much remains
                                        unknown about how users understand, engage with, and evaluate such systems. To
                                        fill this gap, we propose a framework for understanding human-AI interaction in
                                        prompt-based creative tools informed by semi-structured interviews of 19 users.
                                    </p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #82</p>
                                    <p class="title">"Towards End-User Prompt Engineering: Lessons From an LLM-based
                                        Chatbot Design Tool"</p>
                                    <p class="authors">by J.D. Zamfirescu-Pereira, Richmond Wong, Bjorn Hartmann, Qian
                                        Yang</p>
                                    <p class="abstract">Abstract: A large body of prior work has examined the
                                        capabilities of pre-trained language models (&quot;LLMs&quot;) such as GPT-3; in
                                        contrast, relatively little work has explored how humans are able to make use
                                        those capabilities. Using natural language to steer LLM outputs
                                        (&quot;prompting&quot;) is emerging as an important design technique---but
                                        prompt-based systems comply inconsistently, and users face challenges
                                        systematically understanding how a prompt change might impact subsequent LLM
                                        outputs. The apparent ease of instruction via prompts has led to an explosion of
                                        interest in tools that enable end-users to engage with computational systems
                                        using natural language prompts. To explore how these non-expert users approach
                                        &quot;end-user prompt engineering,&quot; we conduct a design probe with a
                                        prototype LLM-based chatbot design tool that encourages iterative development of
                                        prompting strategies, and report briefly on findings here.</p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">15:30</td>
                                <td class="text-light session-time">15:35</td>
                                <td class="text-light session-time">9:30</td>
                                <td class="text-light session-time">9:35</td>
                                <td class="text-light session-name"><strong>discussion</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">15:35</td>
                                <td class="text-light session-time">15:45</td>
                                <td class="text-light session-time">9:35</td>
                                <td class="text-light session-time">9:45</td>
                                <td class="text-light session-name"><strong>short break</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">15:45</td>
                                <td class="text-light session-time">16:00</td>
                                <td class="text-light session-time">9:45</td>
                                <td class="text-light session-time">9:50</td>
                                <td class="text-light session-name"><strong>Panel 3: Creativity + Collaboration</strong>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #11</p>
                                    <p class="title">"The Need for Explainability in AI-Based Creativity Support Tools"
                                    </p>
                                    <p class="authors">by Antonios Liapis, Jichen Zhu</p>
                                    <p class="abstract">Abstract: A long lineage of computer-assisted design tools has
                                        established interaction paradigms that give full control to the designer over
                                        the software. Introduction of Artificial Intelligence (AI) to this creative
                                        process leads to a more co-creative paradigm, with AI taking a more proactive
                                        role. Recent generative approaches based on deep learning have strong potential
                                        as an asset creator and co-creator, however current algorithms are opaque and
                                        burden the designer with making sense of the output. In order for deep learning
                                        to become a colleague that designers can trust and work with, better
                                        explainability, controllability, and interactivity is necessary. We highlight
                                        current and potential ways in which explainability can inform human users in
                                        creative tasks and call for involving end-users in the development of both
                                        interfaces and underlying algorithms.</p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #25</p>
                                    <p class="title">"Quantitatively Assessing Explainability in Collaborative
                                        Computational Co-Creativity"</p>
                                    <p class="authors">by Michael Paul Clemens, Rogelio Enrique Cardona-Rivera, Courtney
                                        Rogers</p>
                                    <p class="abstract">Abstract: While explainable computational creativity (XCC) seeks
                                        to create and sustain computational models of creativity that foster a
                                        collaboratively creative process through explainability, there remains no way of
                                        quantitatively measuring these models. We believe that assessing collaborations
                                        between computational agents and artists will afford designers more confidence
                                        in modeling and creating these agents. Although many creative frameworks assist
                                        in delineating the creative process, we suggest using The Four P's to explore
                                        how creative agents might best co-create with an artist for their respective
                                        creative contributions. Through this research, we propose a framework to assist
                                        designers of co-creative agents in assessing explainability within their
                                        computational models. As a community within both HCI and AI, we believe a
                                        workshop will assist in the direction of this research effort to capture the
                                        appropriate qualities of this framework to maximize effectiveness and utility.
                                    </p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #33</p>
                                    <p class="title">"Embodied Socio-cognitive Reframing of Computational Co-Creativity"
                                    </p>
                                    <p class="authors">by Manoj Deshpande, Brian Magerko</p>
                                    <p class="abstract">Abstract: In this paper, we argue that current definitions of
                                        computational co-creativity do not fully capture embodied and intersubjective
                                        nature prevalent in human co-creation. We lean on theories like human-machine
                                        reconfiguration, embodiment, participatory sense-making, a sociocultural
                                        perspective of creativity, and improvisation to reframe computational
                                        co-creativity. We argue that for an effective co-creative experience with an AI
                                        partner, the agent must have creative agency, sense-making capability, and
                                        facilitate improvisational interaction.</p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">16:00</td>
                                <td class="text-light session-time">16:05</td>
                                <td class="text-light session-time">10:00</td>
                                <td class="text-light session-time">10:05</td>
                                <td class="text-light session-name"><strong>discussion</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">16:05</td>
                                <td class="text-light session-time">16:20</td>
                                <td class="text-light session-time">10:05</td>
                                <td class="text-light session-time">10:20</td>
                                <td class="text-light session-name"><strong>Keynote 3</strong></td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="title">"Independent Community Rooted AI Research"</p>
                                    <p class="authors">by Timnit Gebru, DAIR, US.</p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">16:20</td>
                                <td class="text-light session-time">16:25</td>
                                <td class="text-light session-time">10:20</td>
                                <td class="text-light session-time">10:25</td>
                                <td class="text-light session-name"><strong>discussion</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">16:25</td>
                                <td class="text-light session-time">16:40</td>
                                <td class="text-light session-time">10:25</td>
                                <td class="text-light session-time">10:30</td>
                                <td class="text-light session-name"><strong>Panel 4: Values + Participation</strong>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #39</p>
                                    <p class="title">"Beyond Safety: Toward a Value-Sensitive Approach to the Design of
                                        AI Systems"</p>
                                    <p class="authors">by Alexander J. Fiannaca, Cynthia L. Bennett, Shaun Kane,
                                        Meredith Ringel Morris</p>
                                    <p class="abstract">Abstract: As modern, pre-trained ML models have proliferated in
                                        recent years, many researchers and practitioners have made significant efforts
                                        to prevent AI systems from causing harm. This focus on safety is critical, but a
                                        singular focus on safety can come at the exclusion of considering other
                                        important stakeholder values and the interactions between those values in the AI
                                        systems we build. In this position paper, we propose that the AI community
                                        should incorporate ideas from the Value-Sensitive Design framework from the
                                        Human-Computer Interaction community to ensure the needs and values of all
                                        stakeholders are reflected in the systems we build. We share observations and
                                        reflections from our experiences working on AI-supported accessibility
                                        technologies and with members of various disability communities to illustrate
                                        the tensions that sometimes arise between safety and other values.</p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #53</p>
                                    <p class="title">"Participation Interfaces for Human-Centered AI"</p>
                                    <p class="authors">by Sean McGregor</p>
                                    <p class="abstract">Abstract: Emerging artificial intelligence (AI) applications
                                        often balance the preferences and impacts among diverse and contentious
                                        stakeholder groups. Accommodating these stakeholder groups during system design,
                                        development, and deployment requires tools for the elicitation of disparate
                                        system interests and collaboration interfaces supporting negotiation balancing
                                        interests. This paper introduces interactive visual ``participation interfaces''
                                        for Markov Decision Processes (MDPs) and collaborative ranking problems as
                                        examples restoring a human-centered locus of control.</p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #73</p>
                                    <p class="title">"Expansive Participatory AI: Supporting Dreaming within Inequitable
                                        Institutions"</p>
                                    <p class="authors">by Shiran Dudy</p>
                                    <p class="abstract">Abstract: Participatory Artificial Intelligence (PAI) has
                                        recently gained interest by researchers as means to inform the design of
                                        technology through collective's lived experience. PAI has a greater promise than
                                        that of providing useful input to developers, it can contribute to the process
                                        of democratizing the design of technology, setting the focus on what should be
                                        designed. However, in the process of PAI there existing institutional power
                                        dynamics that hinder the realization of expansive dreams and aspirations of the
                                        relevant stakeholders. In this work we propose co-design principals for AI that
                                        address institutional power dynamics focusing on Participatory AI with youth.
                                    </p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">16:40</td>
                                <td class="text-light session-time">16:45</td>
                                <td class="text-light session-time">10:40</td>
                                <td class="text-light session-time">10:45</td>
                                <td class="text-light session-name"><strong>discussion</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">16:45</td>
                                <td class="text-light session-time">17:15</td>
                                <td class="text-light session-time">10:45</td>
                                <td class="text-light session-time">11:15</td>
                                <td class="text-light session-name"><strong>meal break</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">17:15</td>
                                <td class="text-light session-time">17:30</td>
                                <td class="text-light session-time">11:15</td>
                                <td class="text-light session-time">11:30</td>
                                <td class="text-light session-name"><strong>Keynote 4</strong></td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="title">"Designing AI Systems for Digital Well-Being"</p>
                                    <p class="authors">by Asia Biega, Max Planck Institute for Security and Privacy
                                        (MPI-SP), Germany.</p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">17:30</td>
                                <td class="text-light session-time">17:35</td>
                                <td class="text-light session-time">11:30</td>
                                <td class="text-light session-time">11:35</td>
                                <td class="text-light session-name"><strong>discussion</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">17:35</td>
                                <td class="text-light session-time">17:50</td>
                                <td class="text-light session-time">11:35</td>
                                <td class="text-light session-time">11:40</td>
                                <td class="text-light session-name"><strong>Panel 5: Social Good + Human
                                        Wellbeing</strong></td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #49</p>
                                    <p class="title">"Statelessness in Asylum Data ‚Äì A Human-Centered Perspective on
                                        Outliers"</p>
                                    <p class="authors">by Kristin Kaltenhauser, Naja M√∏ller</p>
                                    <p class="abstract">Abstract: Refugees around the world are increasingly subject to
                                        data-driven decision-making when applying for asylum. In a Danish context, the
                                        amount of data and documentation that is constructed about an asylum-seeker from
                                        various sources and used in the decision-making process has significantly
                                        increased in recent years. We interviewed caseworkers across the immigration
                                        services in Denmark and used this qualitative data to meaningfully engage with a
                                        public data set of Danish asylum decision summaries which is used as a
                                        collaboration tool between organisations. We present initial findings from a
                                        study of statelessness to broaden the understanding of how strengthening human
                                        engagement with data is critical when designing algorithmic systems to support
                                        public and legal decision-making, such as in the asylum domain. We found that
                                        cases of stateless asylum seekers constitute outliers in the data set of Danish
                                        asylum decision summaries, because they require alternative data practices to
                                        constitute the identity of the applicant. Our preliminary findings suggest that
                                        1) we need to pay attention to new forms of data used to construct the asylum
                                        seeker in bureaucracies, for example when it comes to stateless people, and 2)
                                        develop research strategies where stakeholders such as the Danish immigration
                                        services are invited to reflect and develop their practice with an understanding
                                        of data that goes beyond the idea of a plain natural resource.</p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #52</p>
                                    <p class="title">"Another Horizon for Human-Centered AI: An Inspiration to Live
                                        Well"</p>
                                    <p class="authors">by Julian Posada</p>
                                    <p class="abstract">Abstract: This presentation reflects on the role of ideology in
                                        computing and the need for a new horizon in human-centered AI. It discusses how
                                        certain ideologies, from the ‚ÄúCalifornian ideology‚Äù¬†centered on
                                        techno-libertarianism to ‚Äúlongtermism,‚Äù¬†focused on the moral responsibility
                                        for the far future, justify and perpetuate social exploitation. Instead, the
                                        presentation will invite us to look for existing philosophies emerging from
                                        traditionally marginalized peoples as a ‚Äúnew horizon.‚Äù¬†The examples brought
                                        to the discussion are ‚Äúliving well‚Äù¬†perspectives from indigenous Andean and
                                        afro-Colombian roots. Instead of being individualistic and centered on future
                                        outcomes, they stress the importance of human dignity and the relationship
                                        between community and land. The presentation concludes that by focusing on these
                                        essential aspects of human existence, the computing field can find meaningful
                                        ways to address current issues of ethical and societal impacts of artificial
                                        intelligence and other data-driven technologies.</p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #64</p>
                                    <p class="title">"A Future for AI Governance Systems beyond Predictions"</p>
                                    <p class="authors">by Devansh Saxena, Erina Moon, Shion Guha</p>
                                    <p class="abstract">Abstract: Algorithmic systems have been extensively adopted in
                                        various public sector agencies as a means to generate consistent and
                                        evidence-backed decisions to citizens. These AI systems promise to transform how
                                        government agencies interact with people related to how they support information
                                        processing and decision-making. However, prior works show that AI tools largely
                                        fuse onto existing practices and cannot transform public sector work at a deeper
                                        organizational level. In this position paper, we argue that in order to yield
                                        greater use from AI systems and improve decision-making, we need to understand
                                        the discretionary choices workers make as they navigate complex sociotechnical
                                        systems.</p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">17:50</td>
                                <td class="text-light session-time">17:55</td>
                                <td class="text-light session-time">11:50</td>
                                <td class="text-light session-time">11:55</td>
                                <td class="text-light session-name"><strong>discussion</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">17:55</td>
                                <td class="text-light session-time">18:10</td>
                                <td class="text-light session-time">11:55</td>
                                <td class="text-light session-time">12:10</td>
                                <td class="text-light session-name"><strong>Keynote 5</strong></td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="title">"Building human-centric AI systems: thoughts on user agency,
                                        transparency and trust"</p>
                                    <p class="authors">by Fernanda Viegas, Google and Harvard University, US.</p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">18:10</td>
                                <td class="text-light session-time">18:15</td>
                                <td class="text-light session-time">12:10</td>
                                <td class="text-light session-time">12:15</td>
                                <td class="text-light session-name"><strong>discussion</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">18:15</td>
                                <td class="text-light session-time">18:30</td>
                                <td class="text-light session-time">12:15</td>
                                <td class="text-light session-time">12:20</td>
                                <td class="text-light session-name"><strong>Panel 6: Users</strong></td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #54</p>
                                    <p class="title">"(Re)Defining Expertise in Machine Learning Development"</p>
                                    <p class="authors">by Mark Diaz, Angela Smith</p>
                                    <p class="abstract">Abstract: Domain experts are often engaged in the development of
                                        machine learning systems in a variety of ways, such as in data collection and
                                        evaluation of system performance. At the same time, who counts as an
                                        ‚Äòexpert‚Äô and what constitutes ‚Äòexpertise‚Äô is not always explicitly
                                        defined. In this project, we conduct a systematic literature review of machine
                                        learning research to understand 1) the bases on which expertise is defined and
                                        recognized and 2) the roles experts play in ML development. Our goal is to
                                        produce a high-level taxonomy to highlight limits and opportunities in how
                                        experts are identified and engaged in ML research.</p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #71</p>
                                    <p class="title">"A Human-Capabilities Orientation for Human-AI Interaction Design"
                                    </p>
                                    <p class="authors">by Sean Koon</p>
                                    <p class="abstract">Abstract: Many opportunities and challenges accompany the use of
                                        AI in domains with complex human factors and risks. This paper proposes that in
                                        such domains the most advanced human-AI interactions will not arise from an
                                        emphasis on technical capabilities, but rather from an emphasis on understanding
                                        and applying existing human capabilities in new ways. A human-capabilities
                                        orientation is explored along with three aims for research and design.</p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #83</p>
                                    <p class="title">"(De)Noise: Moderating the Inconsistency of Human Decisions"</p>
                                    <p class="authors">by Junaid Ali, Nina Grgic-Hlaca, Krishna P. Gummadi, Jennifer
                                        Wortman Vaughan</p>
                                    <p class="abstract">Abstract: Prior work in social psychology has found that
                                        people‚Äôs decisions are often inconsistent. An individual‚Äôs decisions vary
                                        across time, and decisions vary even more across people. Inconsistencies have
                                        been identified not only in subjective matters, like matters of taste, but also
                                        in settings one might expect to be more objective, such as sentencing, job
                                        performance evaluations, and real estate appraisals. In our study, we explore
                                        whether algorithmic decision aids can be used to moderate the degree of
                                        inconsistency in human decision-making, focusing on bail decision-making as a
                                        case study. In a series of human-subject experiments we explore how people react
                                        to different cues about their inconsistency, ranging from asking respondents to
                                        review their past decisions to providing respondents with algorithmic advice. We
                                        find that both (i) asking respondents to review their decisions as a series of
                                        pairwise comparisons and (ii) providing respondents with algorithmic advice are
                                        effective strategies for influencing human decisions.</p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">18:30</td>
                                <td class="text-light session-time">18:35</td>
                                <td class="text-light session-time">12:30</td>
                                <td class="text-light session-time">12:35</td>
                                <td class="text-light session-name"><strong>discussion</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">18:35</td>
                                <td class="text-light session-time">19:35</td>
                                <td class="text-light session-time">12:35</td>
                                <td class="text-light session-time">13:35</td>
                                <td class="text-light session-name"><strong>Posters</strong></td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="align-center">More information available below</p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">19:35</td>
                                <td class="text-light session-time">19:45</td>
                                <td class="text-light session-time">13:35</td>
                                <td class="text-light session-time">13:45</td>
                                <td class="text-light session-name"><strong>short break</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">19:45</td>
                                <td class="text-light session-time">20:00</td>
                                <td class="text-light session-time">13:45</td>
                                <td class="text-light session-time">13:50</td>
                                <td class="text-light session-name"><strong>Panel 7: Critical</strong></td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #15</p>
                                    <p class="title">"Supporting Qualitative Coding with Machine-in-the-loop"</p>
                                    <p class="authors">by Matthew K Hong, Francine Chen, Yan-Ying Chen, Matt Klenk</p>
                                    <p class="abstract">Abstract: A prevailing assumption underlying machine learning
                                        research for qualitiative coding is that the goal of machine learning is limited
                                        to automating data annotation. Research in machine-assisted qualitative data
                                        analysis has primarily considered a narrow interpretation of this goal, where
                                        the human role is reduced to providing training data for ML models to apply
                                        learned associations to large sets of unstructured text corpora. In this paper,
                                        we argue for the need to embrace a machine-in-the-loop approach that prioritizes
                                        human-centered needs and suggest how to incorporate MITL computing into the
                                        initial data exploration and code identification process.</p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #41</p>
                                    <p class="title">"``Today we talk to the machine'' - Unveiling data for providing
                                        micro-credit loans using conversational systems"</p>
                                    <p class="authors">by Heloisa Candello, Emilio Vital Brazil, Rogerio De Paula,
                                        Cassia Sanctos, Marcelo Grave, Gabriel Soella, Marina Ito, Adinan Brito Filho
                                    </p>
                                    <p class="abstract">Abstract: In this positional paper, we aim to explore the
                                        nuances of designing and developing a conversational user interface for
                                        small-business owners in vulnerable situations. By unveiling and considering
                                        alternative-criteria for providing micro-credit loans, conversational systems
                                        can help financial institutions to deliver micro-credit offerings more
                                        effectively and with justice. We describe a pilot study with 34 entrepreneur
                                        women in which they were invited to use a business health assessment chatbot
                                        prototype, and analyze the experience a focus-group with a sub-set of those
                                        women. We conclude by discussing some insights on the use conversational systems
                                        in support of small-business entrepreneurs.</p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #60</p>
                                    <p class="title">"Towards Multi-faceted Human-centered AI"</p>
                                    <p class="authors">by Sajjadur Rahman, Hannah Kim, Dan Zhang, Estevam Hruschka, Eser
                                        Kandogan</p>
                                    <p class="abstract">Abstract: Human-centered AI workflows involve stakeholders with
                                        multiple roles interacting with each other and automated agents to accomplish
                                        diverse tasks. In this paper, we call for a holistic view when designing support
                                        mechanisms, such as interaction paradigms, interfaces, and systems, for these
                                        multifaceted workflows.</p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">20:00</td>
                                <td class="text-light session-time">20:05</td>
                                <td class="text-light session-time">14:00</td>
                                <td class="text-light session-time">14:05</td>
                                <td class="text-light session-name"><strong>discussion</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">20:05</td>
                                <td class="text-light session-time">20:20</td>
                                <td class="text-light session-time">14:05</td>
                                <td class="text-light session-time">14:20</td>
                                <td class="text-light session-name"><strong>Keynote 6</strong></td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="title">"Why HCAI Needs the Humanities"</p>
                                    <p class="authors">by Lauren Klein, Emory University, US.</p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">20:20</td>
                                <td class="text-light session-time">20:25</td>
                                <td class="text-light session-time">14:20</td>
                                <td class="text-light session-time">14:25</td>
                                <td class="text-light session-name"><strong>discussion</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">20:25</td>
                                <td class="text-light session-time">20:40</td>
                                <td class="text-light session-time">14:25</td>
                                <td class="text-light session-time">14:30</td>
                                <td class="text-light session-name"><strong>Panel 8: Data Work</strong></td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #2</p>
                                    <p class="title">"Labeling instructions matter in biomedical image analysis. An
                                        annotator-centric perspective."</p>
                                    <p class="authors">by Tim R√§dsch, Annika Reinke, Vivienn Weru, Minu D. Tizabi,
                                        Nicholas Schreck, A. Emre Kavur, B√ºnyamin Pekdemir, Tobias Ro√ü, Annette
                                        Kopp-Schneider, Lena Maier-Hein</p>
                                    <p class="abstract">Abstract: Biomedical image analysis algorithm validation depends
                                        on high-quality annotation of reference datasets, for which labeling
                                        instructions are key. Despite the importance of these instructions, their
                                        optimization remains largely unexplored. Here, we present the first systematic
                                        study of labeling instructions and their impact on annotation quality in the
                                        field from an annotator-centric perspective. Through comprehensive examination
                                        of professional practice by surveying 298 professional annotators and
                                        investigating the mandatory BIAS statements of 96 major international biomedical
                                        image analysis competition tasks, we uncovered a discrepancy between
                                        annotators‚Äô needs for labeling instructions and their current quality and
                                        availability. Based on an analysis of 14,040 images annotated by 156 annotators
                                        from four professional companies and 708 Amazon Mechanical Turk (MTurk)
                                        crowdworkers using instructions with different information density levels, we
                                        further found that including exemplary images significantly boosts annotation
                                        performance compared to text-only descriptions, while solely extending text
                                        descriptions does not. Finally, professional annotators constantly outperform
                                        MTurk crowdworkers. Our study raises awareness for the need of quality standards
                                        in biomedical image analysis labeling instructions.</p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #17</p>
                                    <p class="title">"Ground(less) Truth: The Problem with Proxy Outcomes in Human-AI
                                        Decision-Making"</p>
                                    <p class="authors">by Luke Guerdan, Amanda Lee Coston, Steven Wu, Ken Holstein</p>
                                    <p class="abstract">Abstract: A growing literature on human-AI decision-making
                                        investigates strategies for combining human judgment with statistical models to
                                        improve the quality and efficiency of decision-making. Existing research in this
                                        area typically evaluates proposed improvements to models, interfaces, or
                                        workflows by demonstrating improved predictive performance on &quot;ground
                                        truth&quot; labels. However, this practice assumes that labels targeted by
                                        models adequately reflect the goals and objectives of human decision-makers. In
                                        contrast, labels observed in historical data often represent imperfect proxies
                                        for the true phenomena of interest to humans. We identify key statistical biases
                                        that can impact the validity of labels targeted by predictive models in
                                        real-world contexts, and assess the extent to which existing human-AI
                                        decision-making studies consider these challenges. Our analysis identifies
                                        systematic blind spots and assumptions made by existing studies, and motivates
                                        the development of measures of human-AI decision quality beyond accuracy on
                                        proxy outcomes.</p>
                                </td>
                            </tr>
                            <tr>
                                <td class="sessionInfo" colspan="5">
                                    <p class="submission-number">Submision #85</p>
                                    <p class="title">"Human-centered Proposition for Structuring Data Construction"</p>
                                    <p class="authors">by Cheul Young Park, Inha Cha, Juhyun Oh</p>
                                    <p class="abstract">Abstract: As the saying goes, &quot;Garbage in, Garbage
                                        out.&quot; Data significantly impacts dataset quality and model performance.
                                        However, data is notorious for its human-centric nature, making it subjective
                                        and complex. Constructing the data for ML systems requires human interventions,
                                        which cannot be easily quantified or structured. Therefore, ML practitioners
                                        undergo an iterative process of trials and errors, ad hoc solutions, and
                                        heterogeneous methods, which calls for standardization and structured data work.
                                        In this work, we suggest human-centric propositions for structured data
                                        construction.</p>
                                </td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">20:40</td>
                                <td class="text-light session-time">20:45</td>
                                <td class="text-light session-time">14:40</td>
                                <td class="text-light session-time">14:45</td>
                                <td class="text-light session-name"><strong>discussion</strong></td>
                            </tr>
                            <tr class="text-light session-header">
                                <td class="text-light session-time">20:45</td>
                                <td class="text-light session-time">21:00</td>
                                <td class="text-light session-time">14:45</td>
                                <td class="text-light session-time">15:00</td>
                                <td class="text-light session-name"><strong>Closing</strong></td>
                            </tr>
                        </table>
                    </div>
                </div>
            </div>
            <div class="col-md-4">
                <div class="card-spacer"></div>
                <div class="card bg-light">
                    <div class="card-body">
                        <h3>Important Dates </h3>
                        <p><strong>Submission:</strong> 2022-09-22 AoE</p>
                        <p><strong>Notification:</strong> 2022-10-20</p>
                        <p><strong>Camera Ready:</strong> To be announced</p>
                        <p><strong>Workshop:</strong> 2022-12-09</p>
                    </div>
                </div>
                <div class="card-spacer"></div>
                <div class="card bg-light">
                    <div class="card-body">
                        <h3>Submissions</h3>
                        <p>Submit your work to OpenReview using the link below.</p><button class="btn btn-primary"
                            disabled> <strike>Submissions Closed</strike></button>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
        integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"
        integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1"
        crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"
        integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM"
        crossorigin="anonymous"></script>
</body>

</html>